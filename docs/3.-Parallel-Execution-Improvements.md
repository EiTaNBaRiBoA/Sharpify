Whenever using parallel calculations, with either the `Parallel` class or with `Task.WhenAll`, more than likely you could benefit greatly from using the alternatives provided here.

To use these alternatives, you need to follow the next steps:

1. Create a type that implements the best suited delegate type, either `IAction` or `IAsyncAction`
2. Create a local instance of that "delegate" type
3. Use the `.Concurrent()` extension that works on any `ICollection<T>` to access special functions that utilize the "delegate" type

# Extensions Methods On `.Concurrent()`

```csharp
public static Task InvokeAsync<T>(this Concurrent<T> concurrentReference, in IAsyncAction<T> action, CancellationToken token = default)
public static void ForEach<T>(this Concurrent<T> concurrentReference, IAction<T> action)
public static Task ForEachAsync<T>(this Concurrent<T> concurrentReference, IAsyncAction<T> action, int degreeOfParallelization = -1, CancellationToken token = default)
```

* `InvokeAsync` will process all the collection in parallel dynamically depending on the system requirements, similar to `Task.WhenAll` which it uses internally.
* `ForEach` will process non-async action in parallel using maximal concurrency.
* `ForEachAsync` is special as it is using the `degreeOfParallelization` parameter to allow a certain number of actions to be executed in parallel. This is not batching where batching would split the collection to a number of parts, this splits the collection as to maintain a certain number of elements in each sub-collection. settings the parameter to `-1` will set the function to process the same number of elements in parallel as the number of CPU threads in the machine. For example, if you have an 8-thread machine, it will process 8 elements in parallel, after that another 8 and so on, until it is finished. This allows much greater control of resource usage.

# Example

To best show how this is used, I will show an example that uses a `List<int>` and for each item in that list it will wait for 2 seconds and add 2 to the number.

## Implementing `IAsyncAction`

Here we can really see the benefits of using `IAsyncAction` instead of a lambda. As it allows greater control over the properties and their signatures, and vastly more room for optimization by the JIT compiler.

First implement the interface (we can use `strucs` to reduce memory allocations:
```csharp
public readonly struct ParallelListFunction : IAsyncAction<int> { }
```
There is only one method to implement which is `async Task InvokeAsync(int input)` and we will do that later, but we need to store the outputs somewhere, possibly some constants, and being a class with the possibilities of readonly properties and constructors, and even static stuff such as fields, we will use this to our advantage.

## Creating Fields And Custom Constructor
```csharp
private readonly ConcurrentDictionary<int, int> _dict;
private static readonly TimeSpan _delay = TimeSpan.FromSeconds(2);

public ParallelListFunction(ConcurrentDictionary<int, int> outputDict) {
    _dict = outputDict;
}
```

We now have a static readonly field for the delay which reduces memory allocation and increases performance, and a readonly inject field which will hold the reference to our output dictionary.

Now we can implement the main function, take note the the `input` is the element it pulls from the collection.

## Implementing `InvokeAsync`
```csharp
public async Task InvokeAsync(int input) {
    await Task.Delay(delay);
    _dict[input] = input + 2;
}
```
Now we have finished the implementation of the parallel action, we can go the call site and use the following code to execute it.

## Performing The Parallel Calculation
```csharp
List<int> lst = ...
ConcurrentDictionary<int, int> outputDict = new();
var processor = new ParallelListFunction(outputDict); // Using the new constructor we added.
await lst.Concurrent().ForEachAsync(processor);
// Now the output dict is populated with the results.
```

While for this example, this requires much more code than using a lambda, it will considerably reduce memory allocation. As the function that is done in parallel gets longer and more complicated, the readability, maintainability, debugging, and performance will increase exponentially.

# Notes

* All the methods which will have an optional parameter of a `CancellationToken` will actually cancel the parallel execution, as you might know, `Task.WhenAll` isn't very easy to cancel by default.
* The `Concurrent()` extension is required to both separate these functions from the native ones, and make sure the user knows which is the one he is using. And to enforce them only being used on types that implement the `ICollection<T>` interface, which allows optimization using the `Count` property and faster iteration.